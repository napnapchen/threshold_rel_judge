{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1a4cc3-c0fe-4d0e-85b4-4f74ec991bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nov 05, 2024 4:54:37 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "import json\n",
    "\n",
    "searcher = LuceneSearcher.from_prebuilt_index('msmarco-v1-passage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552aea2-50fd-4b40-864c-c9c9934e0f0c",
   "metadata": {},
   "source": [
    "# API KEY 记得删"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd30bd88-3379-4265-990c-915485c86a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\"\"\"\n",
    "API KEY FOR OPENAI\n",
    "\"\"\"\n",
    "API_KEY = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = API_KEY\n",
    "\n",
    "import replicate\n",
    "\n",
    "from replicate.client import Client\n",
    "\"\"\"\n",
    "API KEY FOR REPLICATE\n",
    "\"\"\"\n",
    "replicate_api = Client(api_token=\"\")\n",
    "\n",
    "\"\"\"\n",
    "API KEY FOR GEMINI\n",
    "\"\"\"\n",
    "API_KEY_GEMINI = \"\"\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=API_KEY_GEMINI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5312d6-c249-49a3-a977-abc52be63bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Path to the uploaded file\\nfile_path = './data/2019qrels-pass.txt'\\n\\n# Load the file into a DataFrame, assuming the separator is a space\\ndf = pd.read_csv(file_path, sep=' ', header=None, names=['Topic', 'Q0', 'DocID', 'Relevance'])\\n\\n# Drop the 'Q0' column as it's not needed for this analysis\\ndf.drop('Q0', axis=1, inplace=True)\\n\\n# Group by 'Topic' and 'Relevance' to get the count of each relevance score per topic\\n# Unstack to pivot the 'Relevance' values into separate columns, filling missing values with 0\\nrelevance_distribution = df.groupby(['Topic', 'Relevance']).size().unstack(fill_value=0)\\n\\n# Display the first few rows of the distribution DataFrame\\n# Calculate the proportion of each relevance score within each topic\\nrelevance_proportions = relevance_distribution.div(relevance_distribution.sum(axis=1), axis=0)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "# Path to the uploaded file\n",
    "file_path = './data/2019qrels-pass.txt'\n",
    "\n",
    "# Load the file into a DataFrame, assuming the separator is a space\n",
    "df = pd.read_csv(file_path, sep=' ', header=None, names=['Topic', 'Q0', 'DocID', 'Relevance'])\n",
    "\n",
    "# Drop the 'Q0' column as it's not needed for this analysis\n",
    "df.drop('Q0', axis=1, inplace=True)\n",
    "\n",
    "# Group by 'Topic' and 'Relevance' to get the count of each relevance score per topic\n",
    "# Unstack to pivot the 'Relevance' values into separate columns, filling missing values with 0\n",
    "relevance_distribution = df.groupby(['Topic', 'Relevance']).size().unstack(fill_value=0)\n",
    "\n",
    "# Display the first few rows of the distribution DataFrame\n",
    "# Calculate the proportion of each relevance score within each topic\n",
    "relevance_proportions = relevance_distribution.div(relevance_distribution.sum(axis=1), axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a021edc9-429b-4609-8516-10a325fbecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f9bbc1-11a8-4f6a-b11c-795a0d3e645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_DESCRIPTION_HEAD = \"\\\n",
    "Given a query and a passage, you must provide a score on an integer scale of 0 to 3 with the following meanings: \\n\\\n",
    "0 = represent that the passage has nothing to do with the query, \\n\\\n",
    "1 = represents that the passage seems related to the query but does not answer it, \\n\\\n",
    "2 = represents that the passage has some answer for the query, but the answer may be a bit unclear, \\\n",
    "or hidden amongst extraneous information and \\n\\\n",
    "3 = represents that the passage is dedicated to the query and contains the exact answer. \\n\\n\\\n",
    "Important Instruction: Assign category 1 if the passage is somewhat related to the topic but not completely, \\\n",
    "category 2 if passage presents something very important related to the entire topic but also has some extra information and \\\n",
    "category 3 if the passage only and entirely refers to the topic. If none of the above satisfies give it category 0.\\n\\n\\\n",
    "Next, I will provide you with a batch of documents in the form of {<id_1>: <content_1>, ..., <id_n>: <content_n>}. \\\n",
    "You need to assess their relevance scores and output the result. Your output MUST be in the format of a JSON string \\\n",
    "like {\\\"<id_1>\\\": <relevance_1>, ..., \\\"<id_n>\\\": <relevance_n>}.  Do NOT provide any explain or reasoning. \\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a108fa6a-875b-4e69-8b0f-ecfbd8d9ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_DESCRIPTION_END = \"\\n\\\n",
    "For each passage <passage_i>, split the problem into steps: \\\n",
    "Consider the underlying intent of the search. \\n\\\n",
    "Measure how well the content matches a likely intent of the query (M). \\n\\\n",
    "Decide on a final score <relevance_i>. Final score MUST be an integer value ONLY.\\n\\\n",
    "Directly output the relevance score in the form of JSON, do NOT generate any other content.\\\n",
    "Your output MUST be in the form of {\\\"<id_1>\\\": <relevance_1>, ..., \\\"<id_n>\\\": <relevance_n>}. Do NOT provide any explain or reasoning.\\n\\n\\\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c895ba3a-1f32-42ae-8dc7-8f96b6976a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_content(docid):\n",
    "    # 尝试获取搜索器中的文档\n",
    "    doc = searcher.doc(docid)\n",
    "    if doc is None:\n",
    "        # 如果文档为空，尝试从指定目录读取文本文件\n",
    "        file_path = os.path.join(AUG_DOCS_DIR, docid)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                doc_content = file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(\"No augmented doc file\")\n",
    "            doc_content = None\n",
    "    else:\n",
    "        # 如果文档不为空，从搜索器中提取内容\n",
    "        json_doc = json.loads(doc.raw())\n",
    "        doc_content = json_doc.get('contents', None)\n",
    "    \n",
    "    return doc_content\n",
    "    \n",
    "\n",
    "def create_rel_judge_prompt(query, example_doc_list):\n",
    "    #print(len(example_list))\n",
    "    question_prompt = \"<question>\" + query + \"\\n\"\n",
    "    example_prompt = \"{\"\n",
    "    for i in range(len(example_doc_list)):\n",
    "        example_doc = example_doc_list[i]\n",
    "        docid = example_doc[\"docid\"]\n",
    "        try:\n",
    "            doc_content = get_doc_content(docid)\n",
    "            if i < len(example_doc_list) - 1:\n",
    "                example_prompt += f\"\\\"{docid}\\\": \\\"{doc_content}\\\",\\n\"\n",
    "            else:\n",
    "                example_prompt += f\"\\\"{docid}\\\": \\\"{doc_content}\\\"\\n\"\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(docid)\n",
    "    example_prompt += '}'\n",
    "    return question_prompt + example_prompt + ROLE_DESCRIPTION_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8de981-41d8-48e0-be56-749e951b7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5241b90c-0cc2-4219-91af-081b603e9145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries parsed: 200\n",
      "1108939: what slows down the flow of blood\n",
      "1112389: what is the county for grand rapids, mn\n",
      "792752: what is ruclip\n",
      "1119729: what do you do when you have a nosebleed from having your nose\n",
      "1105095: where is sugar lake lodge located\n"
     ]
    }
   ],
   "source": [
    "def get_query_map(file_path, is_need_print=False):\n",
    "    # Path to the file\n",
    "    #file_path = '/mnt/data/msmarco-test2019-queries.tsv'\n",
    "    \n",
    "    # Initialize an empty dictionary to store the queries\n",
    "    queries_dict = {}\n",
    "    \n",
    "    # Open the file and read line by line\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip the newline character and split the line by the tab delimiter\n",
    "            query_id, query = line.strip().split('\\t')\n",
    "            # Add the query_id and query to the dictionary\n",
    "            queries_dict[query_id] = query\n",
    "    \n",
    "    # (Optional) Print the size of the dictionary and a few example entries\n",
    "    if is_need_print:\n",
    "        print(f'Total queries parsed: {len(queries_dict)}')\n",
    "        for query_id, query in list(queries_dict.items())[:5]:\n",
    "            print(f'{query_id}: {query}')\n",
    "    return queries_dict\n",
    "\n",
    "query_map_mm2019 = get_query_map('./data/msmarco-test2019-queries.tsv', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "261d6c10-ed95-4ee2-8ea1-4b4b51f7b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_ground_truth_xy_list_by_rule(file_path, topic_id, sample_rule=[], black_list=[], my_seed=114514):\n",
    "    # Initialize a dictionary to store topic data\n",
    "    topic_data = {}\n",
    "\n",
    "    # Read the file and populate the dictionary\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' ')\n",
    "            current_topic_id, _, doc_id, relevance_score = int(parts[0]), parts[1], parts[2], int(parts[3])\n",
    "\n",
    "            # Only process entries for the specified topic_id and skip docs in black_list\n",
    "            if (current_topic_id == topic_id or str(current_topic_id) == str(topic_id)) and doc_id not in black_list:\n",
    "                if relevance_score not in topic_data:\n",
    "                    topic_data[relevance_score] = []\n",
    "                topic_data[relevance_score].append(doc_id)\n",
    "\n",
    "    # Check if documents exist for each relevance score in sample_rule\n",
    "    result_docs = []\n",
    "    score_counters = {}\n",
    "\n",
    "    # Randomly sample documents according to the sample_rule\n",
    "    for score in sample_rule:\n",
    "        if score not in score_counters:\n",
    "            score_counters[score] = 0\n",
    "        if score in topic_data:\n",
    "            available_docs = [doc for doc in topic_data[score] if doc not in black_list]\n",
    "            random.seed(my_seed)  # Set the seed for reproducibility\n",
    "            random.shuffle(available_docs)  # Shuffle to randomize the selection\n",
    "\n",
    "            # Take the first available document ID that hasn't been taken yet for the score\n",
    "            if available_docs:\n",
    "                selected_doc_id = available_docs[0]  # Select the first document after shuffling\n",
    "                result_docs.append({\"docid\": selected_doc_id, \"qrel\": score})\n",
    "                topic_data[score].remove(selected_doc_id)  # Remove the selected document to avoid re-selection\n",
    "            else:\n",
    "                raise ValueError(f\"No more documents found for topic {topic_id} with relevance score {score}\")\n",
    "        else:\n",
    "            raise ValueError(f\"No documents available for relevance score {score}\")\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae3296ba-2d97-4be4-b443-d28abf9a0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_ground_truth_xy_list_random(file_path, topic_id, sample_size, my_seed=114514):\n",
    "    # Initialize a dictionary to store documents by their relevance score\n",
    "    topic_data = {}\n",
    "    #print(topic_id)\n",
    "    # Read the file and populate the dictionary\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' ')\n",
    "            current_topic_id, _, doc_id, relevance_score = int(parts[0]), parts[1], parts[2], int(parts[3])\n",
    "            #print(current_topic_id)\n",
    "            # Only process entries for the specified topic_id\n",
    "            if current_topic_id == topic_id or str(current_topic_id) == str(topic_id):\n",
    "                if relevance_score not in topic_data:\n",
    "                    topic_data[relevance_score] = []\n",
    "                topic_data[relevance_score].append(doc_id)\n",
    "\n",
    "    # Collect all documents across all scores for the topic\n",
    "    all_docs = []\n",
    "    for score, docs in topic_data.items():\n",
    "        for doc in docs:\n",
    "            all_docs.append({\"docid\": doc, \"qrel\": score})\n",
    "    #print(all_docs)\n",
    "    # Check if there are enough documents to sample\n",
    "    if len(all_docs) < sample_size:\n",
    "        raise ValueError(f\"Not enough documents to sample: required {sample_size}, available {len(all_docs)}\")\n",
    "\n",
    "    # Set the seed for reproducibility and sample documents\n",
    "    random.seed(my_seed)\n",
    "    selected_docs = random.sample(all_docs, sample_size)\n",
    "\n",
    "    return selected_docs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4342ad3f-afd7-4b63-a55c-bddebf6fd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_doc_id_by_topic(file_path, topic_id):\n",
    "    # Initialize a dictionary to store topic data\n",
    "    result_docs = {}\n",
    "\n",
    "    # Read the file and populate the dictionary\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' ')\n",
    "            current_topic_id, _, doc_id, relevance_score = int(parts[0]), parts[1], parts[2], int(parts[3])\n",
    "\n",
    "            # Only process entries for the specified topic_id and skip docs in black_list\n",
    "            if (current_topic_id == topic_id or str(current_topic_id) == str(topic_id)):\n",
    "                result_docs[doc_id] = relevance_score\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276ceffa-2f04-4abf-a044-ea7a8dee696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_judge_response(batch_prompt, gpt_model=\"gpt-3.5-turbo\"):\n",
    "    # Placeholder for the API call\n",
    "    # Note: Replace the next line with your actual API call\n",
    "    #print(ROLE_DESCRIPTION)\n",
    "    #print(f\"Using model: {gpt_model}\")\n",
    "    os.environ['OPENAI_API_KEY'] = API_KEY\n",
    "    client = OpenAI()\n",
    "    response = None\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "          model=gpt_model,\n",
    "          messages=[\n",
    "            {\n",
    "              \"role\": \"system\",\n",
    "              \"content\":ROLE_DESCRIPTION_HEAD\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":batch_prompt\n",
    "            }\n",
    "        ],\n",
    "          temperature=0,\n",
    "          max_tokens=4096,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.5,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Handle failures by throwing an error and printing it\n",
    "        print(f\"Request Failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529372b1-e1b9-4c99-907f-ea4503b44f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_chat_judge_response(batch_prompt, llama_model=\"llama-2-70b-chat\"):\n",
    "    input_dict = {\n",
    "        \"top_p\": 1,\n",
    "        \"system_prompt\": ROLE_DESCRIPTION_HEAD,\n",
    "        \"prompt\":  batch_prompt,\n",
    "        \"temperature\": 0,\n",
    "        \"max_new_tokens\": 128,\n",
    "        \"min_new_tokens\": -1,\n",
    "        #\"frequency_penalty\":0.5,\n",
    "        #\"presence_penalty\":0,\n",
    "        \"length_penalty\" : 0.01\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        output = replicate_api.run(\n",
    "            \"meta/\"+llama_model,\n",
    "            input=input_dict\n",
    "        )\n",
    "        res = \"\".join(output)\n",
    "        #print(res)\n",
    "        return res\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Handle failures by throwing an error and printing it\n",
    "        print(f\"Request Failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b700b21f-2cd7-46ec-884c-186b014baa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_judge_response(batch_prompt, gemini_model=\"gemini-1.5-pro\"):\n",
    "    g_model = genai.GenerativeModel(gemini_model)\n",
    "    try:\n",
    "        response = g_model.generate_content(\n",
    "            ROLE_DESCRIPTION_HEAD+batch_prompt,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                # Only one candidate for now.\n",
    "                candidate_count=1,\n",
    "                stop_sequences=[\"}\"],\n",
    "                max_output_tokens=1024,\n",
    "                temperature=0,\n",
    "            ),\n",
    "        )\n",
    "        result = response.text + \"}\"\n",
    "        #print(result)\n",
    "        return result\n",
    "                \n",
    "    except Exception as e:\n",
    "        # Handle failures by throwing an error and printing it\n",
    "        print(f\"Request Failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb55399e-60bb-458f-8116-0485bad8a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\"\"\"\n",
    "def extract_key_value(text):\n",
    "    # Define a pattern to match the key-value pairs\n",
    "    pattern = re.compile(r'<relevance_(\\d+)>(\\d+(\\.\\d+)?)')\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = pattern.findall(text)\n",
    "    print(len(matches))\n",
    "    # Convert matches to the desired dictionary format\n",
    "    result = {f\"{match[0]}\": int(match[1]) for match in matches}\n",
    "    \n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "def fix_string_format(str_dict):\n",
    "    # 替换单引号为双引号\n",
    "    str_dict = str_dict.replace(\"'\", \"\\\"\")\n",
    "    \n",
    "    # 使用正则表达式匹配键值对，支持路径和数字作为键\n",
    "    pattern = r'\\\"?([^\\\":]+)\\\"?\\s*:\\s*(\\d+\\.?\\d*)'\n",
    "    items = re.findall(pattern, str_dict)\n",
    "    \n",
    "    fixed_items = []\n",
    "    for key, value in items:\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "        # 检查 key 是否已经被引号包裹\n",
    "        if not (key.startswith(\"\\\"\") and key.endswith(\"\\\"\")):\n",
    "            key = f\"\\\"{key}\\\"\"\n",
    "        fixed_items.append(f\"{key}: {value}\")\n",
    "    \n",
    "    # 将修正后的键值对组合成一个字符串\n",
    "    fixed_str = \"{ \" + \", \".join(fixed_items) + \" }\"\n",
    "    \n",
    "    return fixed_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c62a4aa3-dea1-48b3-bce7-1fa20fa7049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_judge_response(batch_prompt, llm_model):\n",
    "    if llm_model == \"gpt-3.5-turbo\" or llm_model == \"gpt-4o\" or llm_model == \"gpt-4o-mini\":\n",
    "        return get_gpt_judge_response(batch_prompt, llm_model)\n",
    "    elif llm_model == \"llama-2-13b-chat\" or llm_model == \"llama-2-70b-chat\" or llm_model == \"meta-llama-3-70b-instruct\":\n",
    "         return get_llama_chat_judge_response(batch_prompt, llm_model)\n",
    "    elif llm_model == \"gemini-1.5-pro\":\n",
    "        return get_gemini_judge_response(batch_prompt, llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72e42bc-b039-4aaa-aa3f-d3e6f012b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def read_augmented_docs(root_dir):\n",
    "    result = {}\n",
    "    # 遍历 root_dir 下的所有文件和目录\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        parts = root.split(os.sep)\n",
    "        if len(parts) > 4:\n",
    "            collection = parts[2]\n",
    "            topic = parts[3]\n",
    "            score = parts[4]\n",
    "            # 确保字典中有相应的键\n",
    "            if collection not in result:\n",
    "                result[collection] = {}\n",
    "            if topic not in result[collection]:\n",
    "                result[collection][topic] = {}\n",
    "            if score not in result[collection][topic]:\n",
    "                result[collection][topic][score] = []\n",
    "            # 添加文档ID\n",
    "            for file in files:\n",
    "                if file == '.DS_Store':\n",
    "                    continue  # 跳过 .DS_Store 文件\n",
    "                doc_id = f\"{collection}/{topic}/{score}/{file}\"\n",
    "                result[collection][topic][score].append(doc_id)\n",
    "\n",
    "    # 将结果转换为 JSON 格式\n",
    "    #return json.dumps(result, indent=4)\n",
    "    return result\n",
    "\n",
    "# 使用示例\n",
    "#root_directory = './gen_docs'\n",
    "#output = read_augmented_docs(root_directory)\n",
    "#print(output)\n",
    "\n",
    "def get_augmented_ground_truth_xy_list(topic_id, head_rule, augmented_rel_map, user_seed=None):\n",
    "    if user_seed is not None:\n",
    "        random.seed(user_seed)  # 设置随机种子以便测试或复现结果\n",
    "\n",
    "    result = []\n",
    "    seen_docs = set()  # 用于记录已选择的文档，避免重复\n",
    "\n",
    "    # 遍历 head_rule 中的每个分数\n",
    "    for score in head_rule:\n",
    "        possible_docs = augmented_rel_map[topic_id][str(score)]  # 取得该分数下的所有文档列表\n",
    "        filtered_docs = [doc for doc in possible_docs if doc not in seen_docs]  # 过滤已选择的文档\n",
    "\n",
    "        if not filtered_docs:\n",
    "            raise ValueError(f\"No more unique documents available for score {score} and topic {topic_id}\")\n",
    "\n",
    "        selected_doc_id = random.choice(filtered_docs)  # 随机选择一个文档\n",
    "        seen_docs.add(selected_doc_id)  # 标记为已选择\n",
    "\n",
    "        result.append({\"docid\": selected_doc_id, \"qrel\": score})\n",
    "\n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e630487-8936-4576-8e0b-8ad3dbfc9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def judge_docs_by_topic(qrel_file_path, query_map, augmented_doc_map, topic_id, head_rule, tail_length, turn_number, llm_model=\"gpt-4o-mini\",user_seed=None):\n",
    "    #print(rel_judge_prompt)\n",
    "    flag_success = False\n",
    "    retry = 0\n",
    "    value_dict = {}\n",
    "    \n",
    "    while flag_success == False and retry < RETRY_MAX:\n",
    "        if user_seed:\n",
    "            myseed = user_seed\n",
    "        else:\n",
    "            myseed =  114 * turn_number + 514 + retry\n",
    "        list_for_judge_tail = get_ground_truth_xy_list_random(qrel_file_path, topic_id,  tail_length,  my_seed=myseed)\n",
    "        tail_id_list =  [doc['docid'] for doc in list_for_judge_tail]\n",
    "        \n",
    "        list_for_judge_head = get_augmented_ground_truth_xy_list(topic_id, head_rule, augmented_doc_map, user_seed=myseed)\n",
    "        list_for_judge_all = list_for_judge_head + list_for_judge_tail\n",
    "        query = query_map[topic_id]\n",
    "        \n",
    "        #ground_truth_map = {}\n",
    "        #for doc in list_for_judge_tail:\n",
    "        #    ground_truth_map[doc['docid']] = doc['qrel']\n",
    "        #print(ground_truth_map)\n",
    "        #print(list_for_judge_all)\n",
    "        rel_judge_list_prompt = create_rel_judge_prompt(query, list_for_judge_all)  \n",
    "        try:\n",
    "            result = get_llm_judge_response(rel_judge_list_prompt, llm_model)\n",
    "            #print(result)\n",
    "            try:\n",
    "                # 修正字符串格式并将其转换为字典\n",
    "                fixed_str = fix_string_format(result)\n",
    "                value_dict = json.loads(fixed_str)\n",
    "                if len(list_for_judge_all) == len(value_dict.keys()):\n",
    "                    flag_success = True\n",
    "                else:\n",
    "                    print(f\"Unmatched length found: {len(list_for_judge_all)} and {len(value_dict.keys())} topic {topic_id} turn {turn_number} retry{retry}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error when parsing result: topic {topic_id} turn {turn_number} retry {retry}\")\n",
    "                print(e)\n",
    "                print(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error when requesting api. topic:{topic_id} turn {turn_number} retry {retry}\")\n",
    "            print(e)\n",
    "        retry += 1\n",
    "    if not flag_success:\n",
    "        print(f\"Turn failed: topic:{topic_id} turn {turn_number}\")\n",
    "\n",
    "    return value_dict, flag_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff1f90b7-7d2a-4f88-9fc7-57d1ad95b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IS_WITH_EXPLAIN = False\n",
    "with_explain = \"\"\n",
    "if not IS_WITH_EXPLAIN:\n",
    "    with_explain = \"_no_explain\"\n",
    "'''\n",
    "TOPIC_LIST_MAP = {\n",
    "        \"TRDL19\":[\n",
    "        \"47923\",\n",
    "        \"87452\",\n",
    "        \"130510\",\n",
    "        \"168216\",\n",
    "        \"183378\",\n",
    "        \"264014\",\n",
    "        \"359349\",\n",
    "        \"443396\",\n",
    "        \"451602\",\n",
    "        \"527433\",\n",
    "        \"833860\",\n",
    "        \"915593\",\n",
    "        \"1106007\",\n",
    "        \"1110199\",\n",
    "        \"1112341\",\n",
    "        \"1114646\",\n",
    "        \"1114819\",\n",
    "        \"1117099\",\n",
    "        \"1124210\",\n",
    "        \"1133167\"\n",
    "    ],\n",
    "    \"TRDL20\":[\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "QREL_DIR_MAP = {\n",
    "    \"TRDL19\": './data/2019qrels-pass.txt',\n",
    "    \"TRDL20\": './data/2020qrels-pass.txt'\n",
    "}\n",
    "\n",
    "QUERY_DIR_MAP = {\n",
    "    \"TRDL19\":'./data/msmarco-test2019-queries.tsv',\n",
    "    \"TRDL20\": './data/msmarco-test2020-queries.tsv'\n",
    "}\n",
    "\n",
    "AUG_DOCS_DIR = './gen_docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1223d0f-5118-48aa-b14e-6e933053a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def save_result(collection, gpt_model, struct_str, result, save_dir = f'./batch/unknown_collection/random/',custom_str=None):\n",
    "    # 定义文件路径\n",
    "    if save_dir:\n",
    "        directory = save_dir\n",
    "    if not custom_str:\n",
    "        file_path = f'{directory}PredictScore_{gpt_model}_{struct_str}.json'\n",
    "    else:\n",
    "        file_path = f'{directory}PredictScore_{gpt_model}_{struct_str}_{custom_str}.json'\n",
    "\n",
    "    # 检查路径是否存在，如果不存在则创建\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # 保存结果到文件\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b87da9d-a174-4b7d-b884-822a16287ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(collection, gpt_model, gt_str, custom_str=None):\n",
    "    # 定义文件路径\n",
    "    directory = f'./batch/{collection}/new/'\n",
    "    file_path = f'{directory}predict_score_by_{gpt_model}_{gt_str}_{custom_str}.json'\n",
    "    result_map = {}\n",
    "    # 读取 JSON 文件并保存到变量 result_map\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        result_map = json.load(file)\n",
    "    #except:\n",
    "    #    print(\"Something went wrong\")\n",
    "        \n",
    "    return result_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08256af0-393d-4a18-9f7f-242183247df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_LOOP_MAX = 50\n",
    "RETRY_MAX = 5\n",
    "\n",
    "from tqdm import tqdm\n",
    "def run_min_threshold_judge(collection, head_length, tail_length, low_val=0, high_val=3, gpt_model=\"gpt-4o-mini\", save_dir=\"\" ,custom_str = None):\n",
    "    \n",
    "    query_map = get_query_map(QUERY_DIR_MAP[collection])\n",
    "    qrel_file_dir = QREL_DIR_MAP[collection]\n",
    "    aug_docs_map = read_augmented_docs(AUG_DOCS_DIR )\n",
    "    current_aug_docs_map = aug_docs_map[collection]\n",
    "    result_map = {}\n",
    "    failed_turn = []\n",
    "    # 创建进度条，总的迭代次数为主题数量乘以循环次数\n",
    "    total_iterations = len(TOPIC_LIST_MAP[collection]) * JUDGE_LOOP_MAX\n",
    "    with tqdm(total=total_iterations) as pbar:\n",
    "        for topic in TOPIC_LIST_MAP[collection]:\n",
    "            for turn in range(JUDGE_LOOP_MAX):\n",
    "                head_rule = generate_random_list(HEAD_LEN,1,2)\n",
    "                head_rule_high = get_replaced_list(head_rule, high_val,1)\n",
    "                head_rule_low = get_replaced_list(head_rule, low_val,1)\n",
    "                #tail_rule = generate_random_list(tail_length,0,3)\n",
    "                #print(f\"Processing {topic}\")\n",
    "                key = f\"{topic}_{turn}\"\n",
    "                score_by_gpt_high_threshold, flag_high = judge_docs_by_topic(qrel_file_dir, query_map, current_aug_docs_map, topic, \n",
    "                                                                  head_rule_high, tail_length , turn, gpt_model)\n",
    "                score_by_gpt_low_threshold, flag_low = judge_docs_by_topic(qrel_file_dir, query_map, current_aug_docs_map, topic, \n",
    "                                                                  head_rule_low, tail_length , turn, gpt_model)\n",
    "                #print(score_by_gpt_high_threshold)\n",
    "                #high_threshold_str = 'high_predict'\n",
    "                #low_threshold_str = 'low_predict'\n",
    "                #gt_str = 'gt'\n",
    "                result_map[key] = {\n",
    "                    \"model\": gpt_model,\n",
    "                    \"high_rule\": head_rule_high,\n",
    "                    \"low_rule\": head_rule_low,\n",
    "                    \"head_length\": head_length,\n",
    "                    \"tail_length\": tail_length,\n",
    "                    'high_predict': score_by_gpt_high_threshold,\n",
    "                    'low_predict': score_by_gpt_low_threshold\n",
    "                }\n",
    "                if not (flag_high and flag_low):\n",
    "                    failed_turn.append((topic, turn))\n",
    "                pbar.update(1)\n",
    "    high_head_str = ''.join(str(num) for num in head_rule_high)\n",
    "    low_head_str = ''.join(str(num) for num in head_rule_low)\n",
    "    save_name_str = f'hr_{high_head_str}_lr_{low_head_str}_tl_{tail_length}_turn{JUDGE_LOOP_MAX}'\n",
    "    if custom_str:\n",
    "        save_name_str  += custom_str\n",
    "    if not save_dir:\n",
    "        save_dir = f'./batch/{collection}/random/'\n",
    "    save_result(collection, gpt_model, save_name_str, result_map, save_dir)\n",
    "    return result_map, failed_turn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a71dadf-8930-4025-879a-fb85b4533e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length(result_map, l):\n",
    "    # 遍历双重字典并检查每个 value 字典的 keys 数量\n",
    "    for topic, thresholds in result_map.items():\n",
    "        for threshold, value_dict in thresholds.items():\n",
    "            if len(value_dict) != l:\n",
    "                print(f'Topic: {topic}, Threshold: {threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb50cdb2-383d-4fa3-a56a-cb0f0aad7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "def generate_random_list(list_len,val_min,val_max):\n",
    "    # 使用列表推导生成随机数组\n",
    "    return [random.randint(val_min, val_max) for _ in range(list_len)]\n",
    "\n",
    "\n",
    "def get_replaced_list(original_list, target_value, replace_rate=0.5):\n",
    "    # 计算要替换的元素数量\n",
    "    replace_count = int(len(original_list) * replace_rate)\n",
    "    #print(f\"replace {replace_count} documents\")\n",
    "    \n",
    "    # 随机抽取要替换的索引\n",
    "    indices_to_replace = random.sample(range(len(original_list)), replace_count)\n",
    "    \n",
    "    # 复制原列表以保持原始列表不变\n",
    "    replaced_list = original_list[:]\n",
    "    \n",
    "    # 替换指定索引处的元素\n",
    "    for index in indices_to_replace:\n",
    "        replaced_list[index] = target_value\n",
    "    \n",
    "    return replaced_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7e5cb8-5d23-4984-a66c-c75b5891584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:01<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 4\n",
    "\n",
    "result_map_1, failed_turn_1 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"meta-llama-3-70b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b952b28-535b-42b2-bed4-72e8f8022ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:56:11<00:00,  6.97s/it]\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 2\n",
    "TAIL_LEN = 8\n",
    "\n",
    "result_map_2, failed_turn_2 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"meta-llama-3-70b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca67d217-a8c2-4279-b049-9c5f015613b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 504/1000 [48:35<49:18,  5.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 833860 turn 4 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:38:51<00:00,  5.93s/it]\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 9\n",
    "\n",
    "result_map_3, failed_turn_3 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"meta-llama-3-70b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ece8b6dc-f727-4611-a1f4-efdf70e0f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:23:46<00:00,  5.03s/it]\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 4\n",
    "\n",
    "result_map_4, failed_turn_4 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99a4e08b-6053-4099-b452-2b57d61ae734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 277/1000 [27:46<1:13:11,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 264014 turn 27 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 511/1000 [51:43<43:55,  5.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 833860 turn 11 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 531/1000 [53:38<44:00,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 833860 turn 31 retry0\n",
      "Unmatched length found: 10 and 9 topic 833860 turn 31 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 628/1000 [1:03:08<35:04,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1106007 turn 28 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 675/1000 [1:07:29<31:30,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1110199 turn 25 retry0\n",
      "Unmatched length found: 10 and 9 topic 1110199 turn 25 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 710/1000 [1:10:58<26:26,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1112341 turn 10 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 846/1000 [1:23:47<17:24,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1114819 turn 46 retry0\n",
      "Unmatched length found: 10 and 9 topic 1114819 turn 46 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:38:42<00:00,  5.92s/it]\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 2\n",
    "TAIL_LEN = 8\n",
    "\n",
    "result_map_5, failed_turn_5 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88fe2fec-91a4-4c4a-9f20-7230a598617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 291/1000 [29:20<1:11:22,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 264014 turn 41 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 337/1000 [34:08<1:24:02,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 359349 turn 37 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 511/1000 [53:15<1:11:23,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 833860 turn 11 retry0\n",
      "Unmatched length found: 10 and 9 topic 833860 turn 11 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 531/1000 [55:34<56:48,  7.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 833860 turn 31 retry0\n",
      "Unmatched length found: 10 and 9 topic 833860 turn 31 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 636/1000 [1:07:49<40:16,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1106007 turn 36 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 675/1000 [1:11:56<32:59,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1110199 turn 25 retry0\n",
      "Unmatched length found: 10 and 9 topic 1110199 turn 25 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 730/1000 [1:18:09<28:44,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1112341 turn 30 retry0\n",
      "Unmatched length found: 10 and 9 topic 1112341 turn 30 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 846/1000 [1:31:09<16:53,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1114819 turn 46 retry0\n",
      "Unmatched length found: 10 and 9 topic 1114819 turn 46 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 988/1000 [1:47:32<01:20,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched length found: 10 and 9 topic 1133167 turn 38 retry0\n",
      "Unmatched length found: 10 and 9 topic 1133167 turn 38 retry0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:48:59<00:00,  6.54s/it]\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 9\n",
    "\n",
    "result_map_6, failed_turn_6 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee55ae96-597d-431e-9b59-cd7decbc58bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:46:55<00:00,  6.42s/it] \n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 4\n",
    "\n",
    "result_map_7, failed_turn_7 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "328c4e48-ebc9-48e6-95ac-f8c64d2db75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:32:18<00:00,  5.54s/it]\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 9\n",
    "\n",
    "result_map_8, failed_turn_8 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d6b0161-3ae8-4105-ba80-282e59055f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:35:22<00:00,  5.72s/it]\n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 2\n",
    "TAIL_LEN = 8\n",
    "\n",
    "result_map_9, failed_turn_9 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7b24d9c-b446-4745-bc5f-e7b5655a66cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:54:15<00:00,  6.86s/it]  \n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 4\n",
    "\n",
    "result_map_10, failed_turn_10 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed0339be-572e-465b-a3d5-817897c1789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:11:29<00:00,  7.89s/it] \n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 2\n",
    "TAIL_LEN = 8\n",
    "\n",
    "result_map_11, failed_turn_11 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e32f6e55-cd23-4f0a-becd-df9f6ed253f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:03:25<00:00,  7.41s/it] \n"
     ]
    }
   ],
   "source": [
    "HEAD_LEN = 1\n",
    "TAIL_LEN = 9\n",
    "\n",
    "result_map_12, failed_turn_12 = run_min_threshold_judge(\"TRDL19\", HEAD_LEN, TAIL_LEN , 0, 3, \"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03547628-db94-4b04-b45a-cbd2aadb84c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
